{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a1f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped pages: 47801\n",
      "\n",
      "new year values: [1998, 1999, 1960, 1973]\n",
      "rows: 48000\n",
      "columns: 8\n",
      "\n",
      "data types:\n",
      "rank                        object\n",
      "title                       object\n",
      "Worldwide_Lifetime_Gross     int64\n",
      "Domestic_Lifetime_Gross     object\n",
      "Domestic_%                  object\n",
      "Foreign_Lifetime_Gross       int64\n",
      "Foreign_%                   object\n",
      "year                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "final_list = []\n",
    "for i in range(1, 48000,200):\n",
    "    try:\n",
    "        page = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW&offset=' + str(i)\n",
    "        resp = requests.get(page)\n",
    "        soup = BeautifulSoup(resp.text, 'lxml')\n",
    "        table_data = [x.text for x in soup.select('tr td')[0:1600]]  # trial and error to get the exact positions\n",
    "        temp_list = [table_data[i:i+8] for i in range(0, len(table_data[:-7]), 8)] # put every 5 values in a row\n",
    "        for temp in temp_list:\n",
    "            final_list.append(temp)\n",
    "        if not i%10:\n",
    "            print('getting page:', i)\n",
    "    except Exception as e:\n",
    "        break\n",
    "print('scraped pages:', i)\n",
    "        \n",
    "na_year_idx = [i for i, x in enumerate(final_list) if x[3] == 'n/a']  # get the indexes of the 'n/a' values\n",
    "new_years = [1998, 1999, 1960, 1973]  # got them by checking online\n",
    "\n",
    "print(*[(i, x) for i, x in enumerate(final_list) if i in na_year_idx], sep='\\n')\n",
    "print('new year values:', new_years)\n",
    "\n",
    "for na_year, new_year in zip(na_year_idx, new_years):\n",
    "    final_list[na_year][3] = new_year\n",
    "    print(final_list[na_year], new_year)\n",
    "    \n",
    "\n",
    "regex = '|'.join(['\\$', ',', '\\^'])\n",
    "\n",
    "columns = ['rank', 'title', 'Worldwide_lifetime_Gross','Domestic_Lifetime_Gross','Domestic_%','Foreign_Lifetime_Gross', 'Foreign_%','year']\n",
    "\n",
    "boxoffice_df = pd.DataFrame({\n",
    "    'rank': [(x[0]) for x in final_list],  # convert ranks to integers\n",
    "    'title': [x[1] for x in final_list],  # get titles as is\n",
    "    'Worldwide_Lifetime_Gross': [int(re.sub(regex, '', x[2])) for x in final_list],  # remove special characters and convert to integer\n",
    "    'Domestic_Lifetime_Gross':[(re.sub(regex, '', x[3])) for x in final_list],\n",
    "    'Domestic_%':[(re.sub(regex, '', x[4])) for x in final_list],\n",
    "    'Foreign_Lifetime_Gross':[int(re.sub(regex, '', x[5])) for x in final_list],\n",
    "    'Foreign_%':[(re.sub(regex, '', x[6])) for x in final_list],\n",
    "    'year': [int(re.sub(regex, '',str(x[7]))) for x in final_list],  # remove special characters and convert to integer\n",
    "})\n",
    "print('rows:', boxoffice_df.shape[0])\n",
    "print('columns:', boxoffice_df.shape[1])\n",
    "print('\\ndata types:')\n",
    "print(boxoffice_df.dtypes)\n",
    "boxoffice_df.to_csv('../desktop/file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91b9e4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
